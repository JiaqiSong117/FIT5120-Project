{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j472WjNEzQ1F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xO1H6-qzZvg"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707
    },
    "id": "7A0iE826zWwm",
    "outputId": "bc592d14-0c3c-4925-9c7c-1ef0b1ee4d10"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sysintelligent\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.24.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'nb_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d703e14b79b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mloaded_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"count_vector.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mloaded_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tfidf.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mloaded_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nb_model.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mnews_category\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nb_model.pkl'"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Secret Credentials\n",
    "ACCESS_TOKEN = \"500435442-ZsyX0WGAgAsiK3mPMwCLVZgXaM4mPeLpOZHh46Uc\"\n",
    "ACCESS_TOKEN_SECRET = \"tI6pbzVsXWzNmfUEC07by6ZpJc5d58vu0sKxovxuDQEoY\"\n",
    "CONSUMER_KEY = \"zazEfoGYmcJp8IZCQZYeleORe\"\n",
    "CONSUMER_SECRET = \"JtTfz6C4WaCNZkzmn02U4GkOoilCyiIVKFFknuLgWD51MeVySm\"\n",
    "\n",
    "auth=OAuthHandler(CONSUMER_KEY,CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN,ACCESS_TOKEN_SECRET)\n",
    "api=tweepy.API(auth)\n",
    "\n",
    "tweets=[]\n",
    "retweet=[]\n",
    "likes=[]\n",
    "\n",
    "userx='rihanna'\n",
    "\n",
    "for i in tweepy.Cursor(api.user_timeline, id=userx, tweet_mode='extended').items(200):\n",
    "    tweets.append(i.full_text)\n",
    "    retweet.append(i.retweet_count)\n",
    "    likes.append(i.favorite_count)\n",
    "\n",
    "Twitter_df2=pd.DataFrame({'tweets':tweets,'likes':likes,'retweet':retweet})\n",
    "\n",
    "\n",
    "new_docs=list(Twitter_df2['tweets'])\n",
    "\n",
    "#LOAD MODEL\n",
    "loaded_vec = CountVectorizer(vocabulary=pickle.load(open(\"count_vector.pkl\", \"rb\")))\n",
    "loaded_tfidf = pickle.load(open(\"tfidf.pkl\",\"rb\"))\n",
    "loaded_model = pickle.load(open(\"nb_model.pkl\",\"rb\"))\n",
    "\n",
    "news_category=[]\n",
    "\n",
    "for i in range(len(new_docs)):\n",
    "    X_new_counts = loaded_vec.transform([new_docs[i]])\n",
    "    X_new_tfidf = loaded_tfidf.transform(X_new_counts)\n",
    "    predicted = loaded_model.predict(X_new_tfidf)\n",
    "    news_category.append(predicted)\n",
    "\n",
    "x=[]\n",
    "for i in range(len(news_category)):\n",
    "    x.append(news_category[i][0])\n",
    "\n",
    "set_x=list(set(x))\n",
    "set_x_count=[]\n",
    "\n",
    "for j in range(len(set_x)):\n",
    "    set_x_count.append(x.count(set_x[j]))\n",
    "\n",
    "Tweet_Uni=dict(zip(set_x,set_x_count))\n",
    "\n",
    "count1=list(Tweet_Uni.values())\n",
    "size1=[]\n",
    "for i in count1:\n",
    "    size1.append(i*2)\n",
    "\n",
    "colours=[]\n",
    "c=120\n",
    "for i in range(len(count1)):\n",
    "    c=c+2\n",
    "    colours.append(c)\n",
    "\n",
    "\n",
    "fig1 = go.Figure(data=[go.Scatter(\n",
    "    x=set_x,\n",
    "    y=set_x_count,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color=colours,\n",
    "        size=size1,\n",
    "        showscale=True\n",
    "        )\n",
    ")])\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8NW8_tUI1UJh"
   },
   "outputs": [],
   "source": [
    "import plotly.io \n",
    "\n",
    "plotly.io.write_json(fig1,'twitter1.json',validate=True, pretty=False, remove_uids=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "f2Ykv2KJ3bSS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Twitter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
